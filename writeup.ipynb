{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection and Tracking\n",
    "**by Jean-Paul Wilson**\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The following is a description of a pipeline implemented to detect vehicles in dashcam video. \n",
    "The mains steps involved include: \n",
    "\n",
    "i.) Import vehicle images and non-vehicle images.  \n",
    "ii.) Extract features for each set of images.  \n",
    "iii.) Use the features to train a range of classifiers.  \n",
    "iv.) Split each video frame image into a set of windows of varying sizes to identify vehicles at various distances.  \n",
    "v.) Add a heat map to only use detections that have been located multiple times to remove false positives.   \n",
    "vi.) Modify and Improve process for accurate use on a video stream.  \n",
    "\n",
    "### Feature extraction\n",
    "\n",
    "Three types of images are extracted, namely: \n",
    "- Histograms of the colors\n",
    "- Spatial binning (just making the images a small as possible while keeping the resolution high enough to recognise the vehicle shap).  \n",
    "- Histograms of Gradients. This is a unique signature. There were two methods available for carrying this out, either by using scikit image library, or CV2. CV2 is much faster, although I had issues using it, and so, I used skimage, and sub sampled after extracting the HOG features across the entire image. \n",
    "Visualizing a representation of the HOG features on a set of random images from the dataset, one can see that for certain vehicle and non-vehicle images, the HOG image seems to show the actual vehicle features, but not in all.   \n",
    "Put differently, the correlation between the HOG image and the actual image is sometimes a lot clearer than in other images for some reason. Also, sometimes the HOG image for the car and non car image are completely different, while sometimes they difference is difficult to ascertain from the human eye,  as seen in the 3 image sets below: \n",
    "\n",
    "#### Clear HOG Images\n",
    "<img src = \"writeuppics/HogClear.jpg\">\n",
    "\n",
    "\n",
    "#### Less Clear HOG Images\n",
    "<img src = \"writeuppics/HogLessVague.jpg\">\n",
    "\n",
    "\n",
    "#### Least Clear HOG Images\n",
    "<img src = \"writeuppics/HogVague.jpg\">\n",
    "\n",
    "A trial and error approach, with visual inspection (as in the images above) of the results of trying various parameters was carried out to determine the best combination of parameters to be used for HOG feature extraction. It must be noted that the feature extraction parameters used for the training of the classifier differ from those used in the actual video stream vehicle detection. There values can be found in the notebook attached. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
